# Intro
This is a collection of models for natural language processing (NLP) tasks.
From the most basic models to the current state-of-the-art ideas.
The goal is to get hands-on experience with the models and understand how they
work.

    "What I cannot create, I do not understand." - Richard Feynman


# TODO
- [ ] Review all the models:
    - [ ] ngram
    - [ ] glove
    - [ ] nn-bigram
    - [ ] nnlm
    - [ ] word2vec
    - [ ] glove
    - [ ] fasttext

- [ ] Maybe models:
    - [ ] wavenet

- [ ] Add more models:
    - [ ] RNN
    - [ ] LSTM
    - [ ] GRU
    - [ ] Transformer
    - [ ] bert
    - [ ] gpt
    - [ ] electra
    - [ ] retromae

If there will be space for more models:
- Hidden Markov models (HMMs)
- Decision trees and Random Forests
- Support Vector Machines (SVMs)
- Bayesian Models
- Latent Semantic Analysis (LSA)

# Resources
- based on Andrej Karpathy video series

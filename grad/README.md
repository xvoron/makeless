Mastering backprops and autograd using karpathy micrograd as starting point.

https://github.com/karpathy/micrograd

# TODO:
- [ ] Dataloader:
    - [ ] Batch training
    - [ ] Dataset
- [ ] Losses:
    - [ ] Max-margin
    - [ ] Cross Entropy
    - [ ] Binary Cross Entropy
- [ ] Regularizations:
    - [ ] L1
    - [ ] L2
- [ ] Optimizers:
    - [ ] SGD
    - [ ] Learning rate decay
    - [ ] Adam
- [ ] Metrics:
- [ ] Add visualization for layers:
    - [ ] Histogram
    - [ ] plot as image


